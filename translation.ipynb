{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\83577\\anaconda3\\envs\\torch\\lib\\site-packages\\torchtext\\data\\utils.py:105: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\83577\\anaconda3\\envs\\torch\\lib\\site-packages\\torchtext\\data\\utils.py:105: UserWarning: Spacy model \"de\" could not be loaded, trying \"de_core_news_sm\" instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from models import S2SPL\n",
    "from dataset import en_de_dataset\n",
    "from utils import load_config_json\n",
    "import os\n",
    "from torchtext.data.metrics import bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best\\DEVICEcuda BATCH_SIZE128 LEARNING_RATE0.0001 EPOCHS600 ENCODER_TYPEGRU DECODER_TYPEGRU ATTENTION_HEAD1 ENCODER_LAYERS2 DECODER_LAYERS2 EMB_DIM150 HIDDEN_ENCODER512 HIDDEN_DECODER512 DROPOUT_ENCODER0.5 DROPOUT_DECODER0.5 BIDIRECTIONFalse PAIR('en', 'de')\n",
      "\n",
      "best\\DEVICEcuda BATCH_SIZE128 LEARNING_RATE0.0001 EPOCHS600 ENCODER_TYPEGRU DECODER_TYPEGRU ATTENTION_HEAD1 ENCODER_LAYERS2 DECODER_LAYERS2 EMB_DIM150 HIDDEN_ENCODER512 HIDDEN_DECODER512 DROPOUT_ENCODER0.5 DROPOUT_DECODER0.5 BIDIRECTIONFalse PAIR('en', 'de')\\-epoch=87-valid_loss=3.67-validation.ckpt\n",
      "\n",
      "best\\DEVICEcuda BATCH_SIZE128 LEARNING_RATE0.0001 EPOCHS600 ENCODER_TYPEGRU DECODER_TYPEGRU ATTENTION_HEAD1 ENCODER_LAYERS2 DECODER_LAYERS2 EMB_DIM150 HIDDEN_ENCODER512 HIDDEN_DECODER512 DROPOUT_ENCODER0.5 DROPOUT_DECODER0.5 BIDIRECTIONFalse PAIR('en', 'de')\\config.json\n"
     ]
    }
   ],
   "source": [
    "path = os.listdir('best')[-1] # could be replaced by the folder name\n",
    "path = os.path.join('best', path)\n",
    "\n",
    "checkpoint = '-epoch=87-valid_loss=3.67-validation.ckpt'#os.listdir(path)[0] # could be replaced by your own\n",
    "checkpoint = os.path.join(path, checkpoint)\n",
    "\n",
    "params = os.path.join(path, 'config.json')\n",
    "\n",
    "print(path + '\\n')\n",
    "print(checkpoint + '\\n')\n",
    "print(params)\n",
    "\n",
    "# Initialize args\n",
    "args = load_config_json(params)\n",
    "\n",
    "args['DEVICE'] = 'cpu'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input vocab size: 6191\n",
      "Target vocab size: 8014\n"
     ]
    },
    {
     "data": {
      "text/plain": "S2SPL(\n  (encoder): RNNEncoder(\n    (emb): Embedding(6191, 150)\n    (rnn): GRU(150, 512, num_layers=2, dropout=0.5)\n    (dropout): Dropout(p=0.5, inplace=False)\n  )\n  (decoder): RNNDecoder(\n    (emb): Embedding(8014, 150)\n    (rnn): GRU(150, 512, num_layers=2, dropout=0.5)\n    (dropout): Dropout(p=0.5, inplace=False)\n    (decode): Linear(in_features=512, out_features=8014, bias=True)\n  )\n  (cross_entrophy): CrossEntropyLoss()\n)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial Dataset\n",
    "trainset = en_de_dataset(split='train')\n",
    "# Initialize model parameters\n",
    "s2s_model = S2SPL(\n",
    "        vocab_size_encoder=len(trainset.input_vocab),\n",
    "        vocab_size_decoder=len(trainset.target_vocab),\n",
    "        input_vocab=trainset.input_vocab,\n",
    "        target_vocab=trainset.target_vocab,\n",
    "        input_id_to_word=trainset.id_to_word_input,\n",
    "        target_id_to_word=trainset.id_to_word_target,\n",
    "        args=args\n",
    ")\n",
    "\n",
    "\n",
    "model = s2s_model.load_from_checkpoint(checkpoint)\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "('telefoniert auf der Straße .', 0.0)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model.translate('A man walking on the street.', 'Ein Mann geht am Strasse')\n",
    "output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('In front of an Asian market store one man rests in a chair while another man cleans.', 'Vor einem asiatischen Marktstand ruht sich ein Mann in einem Sessel aus, während ein anderer Mann putzt.')\n",
      "('Vor einem asiatischen Marktstand , Mannes , während ein Mann Mann in einem Sessel sitzt , während ein Mann Mann', 0.285078227519989)\n"
     ]
    }
   ],
   "source": [
    "input_pair, target_pair = trainset.random_pairs()\n",
    "print((input_pair, target_pair))\n",
    "print(model.translate(input_pair, target_pair))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}